#!/usr/bin/env python3
"""
Proteomics Benchmark Framework with Triqler Integration

A comprehensive Streamlit application for multi-species proteomics benchmark analysis
using Bayesian fold-change posteriors from Triqler.

Features:
  - Spectronaut DIA-MS data import and processing
  - Automatic Triqler execution with posterior extraction
  - TOST equivalence testing with proper uncertainty quantification
  - 6-category protein classification system
  - Comprehensive benchmark metrics (deFDR, Cpk, asymmetry, RMSE)
  - Interactive visualizations and reporting

Author: Proteomics Analysis Team
Version: 1.0.0
Status: Production-ready
"""

import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
import tempfile
import subprocess
import os
from dataclasses import dataclass, asdict
from typing import Tuple, Dict, List, Optional
from scipy import stats
from scipy.interpolate import interp1d
from scipy.stats import gaussian_kde
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime
import traceback

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATA CLASSES & TYPE DEFINITIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class ClassificationResult:
    """Classification result for a single protein."""
    protein_id: str
    species: str
    observed_log2fc: float
    expected_log2fc: float
    posterior_mean: float
    posterior_ci_lower: float
    posterior_ci_upper: float
    posterior_std: float
    pep: float
    diff_exp_prob: float
    category: str
    tost_p_value: float
    notes: str


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STATISTICAL FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def tost_equivalence_test(
    posterior_mean: float,
    posterior_std: float,
    expected_fc: float,
    tolerance: float = 0.3,
    alpha: float = 0.05
) -> Tuple[float, bool]:
    """
    Two One-Sided Test (TOST) for equivalence.
    
    Tests whether the 90% credible interval (CI) falls entirely within the 
    equivalence bounds [expected_fc - tolerance, expected_fc + tolerance].
    
    Args:
        posterior_mean: Mean of posterior distribution (log2 fold change)
        posterior_std: Standard deviation of posterior
        expected_fc: Expected fold change (log2)
        tolerance: Equivalence tolerance (Â±Î´ in log2)
        alpha: Significance level (typically 0.05 for 90% CI)
    
    Returns:
        Tuple of (p_value, is_equivalent)
    """
    # 90% CI corresponds to Î±=0.05 for two-sided test
    z_critical = stats.norm.ppf(1 - alpha/2)
    
    # Calculate 90% credible interval
    ci_lower = posterior_mean - z_critical * posterior_std
    ci_upper = posterior_mean + z_critical * posterior_std
    
    # Equivalence bounds
    lower_bound = expected_fc - tolerance
    upper_bound = expected_fc + tolerance
    
    # Check if CI entirely within bounds
    if ci_lower >= lower_bound and ci_upper <= upper_bound:
        # Calculate TOST p-value (max of two one-sided tests)
        t_lower = (posterior_mean - lower_bound) / posterior_std if posterior_std > 0 else np.inf
        t_upper = (upper_bound - posterior_mean) / posterior_std if posterior_std > 0 else np.inf
        
        # One-sided p-values
        p_lower = 1 - stats.norm.cdf(t_lower)
        p_upper = 1 - stats.norm.cdf(t_upper)
        p_value = max(p_lower, p_upper)
        
        is_equivalent = p_value < alpha
    else:
        p_value = 1.0
        is_equivalent = False
    
    return p_value, is_equivalent


def calculate_cpk(observed: np.ndarray, target: float, tolerance: float) -> float:
    """
    Calculate process capability index (Cpk).
    
    Cpk = min(CPU, CPL) where:
      CPU = (USL - mean) / (3 * sigma)
      CPL = (mean - LSL) / (3 * sigma)
      USL = target + tolerance, LSL = target - tolerance
    
    Args:
        observed: Array of observed values
        target: Target/center value
        tolerance: Tolerance bound (Â±)
    
    Returns:
        Cpk value (higher is better, 1.33+ is "capable")
    """
    if len(observed) < 2:
        return np.nan
    
    mean = np.mean(observed)
    sigma = np.std(observed, ddof=1)
    
    # Handle zero sigma
    if sigma == 0:
        return np.nan if abs(mean - target) > tolerance else np.inf
    
    usl = target + tolerance
    lsl = target - tolerance
    
    cpu = (usl - mean) / (3 * sigma)
    cpl = (mean - lsl) / (3 * sigma)
    
    cpk = min(cpu, cpl)
    return max(0, cpk)  # Cpk can't be negative


def calculate_rmse(observed: np.ndarray, expected: float) -> float:
    """
    Calculate Root Mean Square Error.
    
    RMSE = sqrt(mean((observed - expected)^2))
    
    Args:
        observed: Array of observed values
        expected: Expected value
    
    Returns:
        RMSE value
    """
    if len(observed) == 0:
        return np.nan
    
    mse = np.mean((observed - expected) ** 2)
    return np.sqrt(mse)


def calculate_asymmetry_factor(log2fcs: np.ndarray) -> float:
    """
    Calculate asymmetry factor using KDE-based approach.
    
    Detects left/right asymmetry in fold-change distribution at 10% of max density.
    
    Args:
        log2fcs: Array of log2 fold changes
    
    Returns:
        Asymmetry factor (1.0 = symmetric, <1 = left-skewed, >1 = right-skewed)
    """
    if len(log2fcs) < 5:
        return np.nan
    
    try:
        # Remove outliers (beyond Â±5 log2 units)
        log2fcs_clean = log2fcs[(log2fcs >= -5) & (log2fcs <= 5)]
        
        if len(log2fcs_clean) < 5:
            return np.nan
        
        # KDE estimation
        kde = gaussian_kde(log2fcs_clean)
        x_range = np.linspace(log2fcs_clean.min(), log2fcs_clean.max(), 500)
        density = kde(x_range)
        
        # Find peak and 10% height
        peak_idx = np.argmax(density)
        peak_height = density[peak_idx]
        threshold = peak_height * 0.1
        
        # Find x-values where density crosses 10% threshold
        above_threshold = x_range[density >= threshold]
        
        if len(above_threshold) < 2:
            return np.nan
        
        left_edge = above_threshold[0]
        right_edge = above_threshold[-1]
        peak_x = x_range[peak_idx]
        
        left_dist = peak_x - left_edge
        right_dist = right_edge - peak_x
        
        # Asymmetry factor = min_distance / max_distance
        if max(left_dist, right_dist) == 0:
            return np.nan
        
        asym = min(left_dist, right_dist) / max(left_dist, right_dist)
        return asym
        
    except Exception:
        return np.nan


def calculate_defdr(classifications: List[ClassificationResult]) -> float:
    """
    Calculate directional False Discovery Rate (deFDR).
    
    deFDR = (wrong_direction + false_positive) / total_significant
    
    Measures fraction of significant proteins with incorrect classification.
    
    Args:
        classifications: List of ClassificationResult objects
    
    Returns:
        deFDR value (0-1, lower is better)
    """
    # Count significant proteins (diff_exp_prob >= 0.5)
    significant = [c for c in classifications if c.diff_exp_prob >= 0.5]
    
    if len(significant) == 0:
        return 0.0
    
    # Count directional errors
    wrong_direction = sum(1 for c in significant if c.category == 'WRONG_DIRECTION')
    false_positive = sum(1 for c in significant if c.category == 'FALSE_POSITIVE')
    
    defdr = (wrong_direction + false_positive) / len(significant)
    return defdr


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATA PROCESSING FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def format_peptide_sequence(peptide: Optional[str]) -> Optional[str]:
    """
    Format peptide sequence for Triqler.
    
    Triqler expects format: -.SEQUENCE.-
    Removes modifications in square brackets.
    
    Args:
        peptide: Raw peptide sequence (e.g., '_PEPT[Phospho]IDE_')
    
    Returns:
        Formatted sequence (e.g., '-.PEPTIDE.-')
    """
    if peptide is None or peptide == '':
        return None
    
    # Remove leading/trailing underscores
    peptide = peptide.strip('_')
    
    # Remove modifications (text in square brackets)
    import re
    peptide_clean = re.sub(r'\[.*?\]', '', peptide)
    
    # Add Triqler formatting
    return f'-.{peptide_clean}.-'


def infer_species(organism: str, protein_id: str) -> str:
    """
    Infer species from organism name or protein ID.
    
    Args:
        organism: Organism name from data
        protein_id: Protein identifier
    
    Returns:
        Species code ('human', 'yeast', 'ecoli', 'unknown')
    """
    # Convert to lowercase for comparison
    organism_lower = str(organism).lower() if organism else ''
    protein_lower = str(protein_id).lower() if protein_id else ''
    
    # Check organism field
    if 'homo sapiens' in organism_lower or 'human' in organism_lower:
        return 'human'
    if 'saccharomyces' in organism_lower or 'yeast' in organism_lower:
        return 'yeast'
    if 'escherichia' in organism_lower or 'e.coli' in organism_lower or 'ecoli' in organism_lower:
        return 'ecoli'
    
    # Check protein ID field
    if '_human' in protein_lower or 'sp|' in protein_lower and 'HUMAN' in str(protein_id):
        return 'human'
    if '_yeast' in protein_lower or 'YEAST' in str(protein_id):
        return 'yeast'
    if '_ecoli' in protein_lower or 'ECOLI' in str(protein_id):
        return 'ecoli'
    
    return 'unknown'


def convert_to_triqler_format(df: pd.DataFrame) -> pd.DataFrame:
    """
    Convert Spectronaut export to Triqler input format.
    
    Required input columns:
      - R.FileName: Run file name
      - R.Condition: Experimental condition
      - FG.Charge: Precursor charge
      - EG.Cscore: Search score
      - FG.MS2RawQuantity: Raw MS2 intensity
      - EG.ModifiedSequence: Peptide sequence
      - PG.ProteinGroups: Protein identifier
      - EG.IsDecoy: Decoy flag
    
    Output columns: run, condition, charge, searchScore, intensity, peptide, proteins
    
    Args:
        df: Spectronaut export DataFrame
    
    Returns:
        Triqler format DataFrame
    """
    try:
        # Validate required columns
        required = ['R.FileName', 'R.Condition', 'FG.Charge', 'EG.Cscore',
                   'FG.MS2RawQuantity', 'EG.ModifiedSequence', 'PG.ProteinGroups', 'EG.IsDecoy']
        missing = [col for col in required if col not in df.columns]
        
        if missing:
            raise ValueError(f"Missing required columns: {missing}")
        
        # Filter out decoys
        df_filtered = df[~df['EG.IsDecoy']].copy()
        
        # Create Triqler format
        result = pd.DataFrame({
            'run': df_filtered['R.FileName'].str.replace('.raw', '', case=False),
            'condition': df_filtered['R.Condition'],
            'charge': df_filtered['FG.Charge'].astype(int),
            'searchScore': df_filtered['EG.Cscore'].astype(float),
            'intensity': df_filtered['FG.MS2RawQuantity'].astype(float),
            'peptide': df_filtered['EG.ModifiedSequence'].apply(format_peptide_sequence),
            'proteins': df_filtered['PG.ProteinGroups'].astype(str)
        })
        
        # Remove rows with None peptides
        result = result.dropna(subset=['peptide'])
        
        return result
        
    except Exception as e:
        raise ValueError(f"Conversion failed: {str(e)}")


def extract_triqler_posteriors(protein_posteriors_file: str, 
                               fold_change_posteriors_file: str) -> Dict:
    """
    Extract posterior statistics from Triqler output files.
    
    Triqler outputs grid-based posteriors; this extracts mean, std, and 90% CI.
    
    Args:
        protein_posteriors_file: Path to protein_posteriors.tsv
        fold_change_posteriors_file: Path to fold_change_posteriors.tsv
    
    Returns:
        Dictionary mapping protein_id -> {'mean': float, 'std': float, 'ci_lower': float, 'ci_upper': float}
    """
    posteriors = {}
    
    try:
        if not os.path.exists(fold_change_posteriors_file):
            return posteriors
        
        df = pd.read_csv(fold_change_posteriors_file, sep='\t')
        
        for _, row in df.iterrows():
            protein_id = row.get('protein_id') or row.get('Protein')
            
            if protein_id is None:
                continue
            
            # Extract grid-based posterior
            # Triqler outputs a grid; calculate statistics from it
            grid_col = [col for col in df.columns if 'grid' in col.lower()]
            
            if grid_col:
                # Parse grid values
                grid_str = row[grid_col[0]]
                try:
                    grid_vals = np.array([float(x) for x in str(grid_str).split()])
                    mean_est = np.mean(grid_vals)
                    std_est = np.std(grid_vals)
                except:
                    mean_est = float(row.get('mean', np.nan))
                    std_est = float(row.get('std', np.nan))
            else:
                mean_est = float(row.get('mean', np.nan))
                std_est = float(row.get('std', np.nan))
            
            # 90% CI (z=1.645 for 90%)
            z_90 = 1.645
            ci_lower = mean_est - z_90 * std_est
            ci_upper = mean_est + z_90 * std_est
            
            posteriors[str(protein_id)] = {
                'mean': mean_est,
                'std': std_est,
                'ci_lower': ci_lower,
                'ci_upper': ci_upper
            }
        
        return posteriors
        
    except Exception as e:
        st.warning(f"Could not extract posteriors: {str(e)}")
        return posteriors


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLASSIFICATION & METRICS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def classify_protein(protein_id: str,
                    observed_log2fc: float,
                    expected_log2fc: float,
                    posterior_mean: float,
                    posterior_std: float,
                    posterior_ci_lower: float,
                    posterior_ci_upper: float,
                    pep: float,
                    diff_exp_prob: float,
                    tolerance: float = 0.3,
                    alpha: float = 0.05) -> Tuple[str, float, str]:
    """
    Classify a protein into 6 categories based on posterior statistics.
    
    Categories:
      1. CORRECT - Expected direction + within tolerance
      2. WRONG_MAGNITUDE - Correct direction + outside tolerance
      3. WRONG_DIRECTION - Opposite direction + significant
      4. FALSE_POSITIVE - Background showing unexpected change
      5. TRUE_NEGATIVE - Background correctly not changing
      6. NOT_SIGNIFICANT - No statistical evidence
    
    Args:
        protein_id: Protein identifier
        observed_log2fc: Observed log2 fold change
        expected_log2fc: Expected log2 fold change
        posterior_mean: Mean of posterior
        posterior_std: Standard deviation of posterior
        posterior_ci_lower: Lower CI bound
        posterior_ci_upper: Upper CI bound
        pep: Posterior error probability
        diff_exp_prob: Probability of differential expression
        tolerance: Equivalence tolerance (Â±Î´)
        alpha: Significance level
    
    Returns:
        Tuple of (category, tost_p_value, notes)
    """
    # Significance threshold
    is_significant = diff_exp_prob >= 0.5
    
    # Is expected to change?
    expected_to_change = abs(expected_log2fc) > 0.01
    
    # TOST equivalence test
    tost_p, is_equivalent = tost_equivalence_test(
        posterior_mean, posterior_std, expected_log2fc, tolerance, alpha
    )
    
    # Determine category
    if expected_to_change:
        # Species that should show change (yeast, ecoli, etc.)
        if is_significant:
            # Significant change detected
            sign_expected = np.sign(expected_log2fc)
            sign_observed = np.sign(posterior_mean)
            
            if sign_expected == sign_observed:
                # Correct direction
                if is_equivalent:
                    category = 'CORRECT'
                    notes = 'Within tolerance'
                else:
                    category = 'WRONG_MAGNITUDE'
                    notes = 'Outside tolerance'
            else:
                # Wrong direction
                category = 'WRONG_DIRECTION'
                notes = 'Opposite direction'
        else:
            # Not significant
            category = 'NOT_SIGNIFICANT'
            notes = 'No signal detected'
    else:
        # Background species (human) - should NOT change
        if is_significant:
            # Unexpected change
            category = 'FALSE_POSITIVE'
            notes = 'Unexpected change in background'
        else:
            # Correct - no change
            category = 'TRUE_NEGATIVE'
            notes = 'Correctly stable'
    
    return category, tost_p, notes


def classify_proteins(data_with_posteriors: pd.DataFrame,
                     expected_fold_changes: Dict[str, float],
                     tolerance: float = 0.3,
                     alpha: float = 0.05) -> List[ClassificationResult]:
    """
    Classify all proteins in dataset.
    
    Args:
        data_with_posteriors: DataFrame with protein data and posteriors
        expected_fold_changes: Dict mapping species -> expected log2 fold change
        tolerance: Equivalence tolerance
        alpha: Significance level
    
    Returns:
        List of ClassificationResult objects
    """
    classifications = []
    
    for _, row in data_with_posteriors.iterrows():
        protein_id = str(row['protein_id'])
        species = str(row['species'])
        
        expected_fc = expected_fold_changes.get(species, 0.0)
        
        category, tost_p, notes = classify_protein(
            protein_id=protein_id,
            observed_log2fc=float(row['observed_log2fc']),
            expected_log2fc=expected_fc,
            posterior_mean=float(row['posterior_mean']),
            posterior_std=float(row['posterior_std']),
            posterior_ci_lower=float(row['posterior_ci_lower']),
            posterior_ci_upper=float(row['posterior_ci_upper']),
            pep=float(row.get('pep', 0.01)),
            diff_exp_prob=float(row.get('diff_exp_prob', 0.5)),
            tolerance=tolerance,
            alpha=alpha
        )
        
        result = ClassificationResult(
            protein_id=protein_id,
            species=species,
            observed_log2fc=float(row['observed_log2fc']),
            expected_log2fc=expected_fc,
            posterior_mean=float(row['posterior_mean']),
            posterior_ci_lower=float(row['posterior_ci_lower']),
            posterior_ci_upper=float(row['posterior_ci_upper']),
            posterior_std=float(row['posterior_std']),
            pep=float(row.get('pep', 0.01)),
            diff_exp_prob=float(row.get('diff_exp_prob', 0.5)),
            category=category,
            tost_p_value=tost_p,
            notes=notes
        )
        
        classifications.append(result)
    
    return classifications


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TRIQLER EXECUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_triqler(triqler_input_file: str, output_dir: str) -> Dict:
    """
    Execute Triqler with proper subprocess handling.
    
    âœ… FIXED: Uses correct snake_case argument names
    - --missing_value_prior (not --missingValuePrior)
    - --min_samples (not --minSamples)
    - --num_threads (not --numThreads)
    - --write_protein_posteriors (not --writeProteinPosteriors)
    - --write_fold_change_posteriors (not --writeFoldChangePosteriors)
    
    Args:
        triqler_input_file: Path to Triqler input TSV
        output_dir: Output directory for results
    
    Returns:
        Dictionary with result status and file paths
    """
    try:
        protein_posteriors_file = os.path.join(output_dir, 'protein_posteriors.tsv')
        fold_change_posteriors_file = os.path.join(output_dir, 'fold_change_posteriors.tsv')
        
        # Construct command with CORRECT snake_case arguments
        cmd = [
            'python', '-m', 'triqler',
            '--missing_value_prior', str(0.6),           # âœ… FIXED: snake_case
            '--min_samples', str(1),                     # âœ… FIXED: snake_case
            '--num_threads', str(4),                     # âœ… FIXED: snake_case
            '--write_protein_posteriors', str(protein_posteriors_file),    # âœ… FIXED: snake_case
            '--write_fold_change_posteriors', str(fold_change_posteriors_file),  # âœ… FIXED: snake_case
            str(triqler_input_file)
        ]
        
        # Execute subprocess
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=3600
        )
        
        if result.returncode != 0:
            error_msg = result.stderr or result.stdout
            raise Exception(f"Triqler failed: {error_msg}")
        
        return {
            'success': True,
            'protein_posteriors': protein_posteriors_file,
            'fold_change_posteriors': fold_change_posteriors_file,
            'message': 'Triqler completed successfully'
        }
        
    except subprocess.TimeoutExpired:
        return {
            'success': False,
            'error': 'Triqler execution timed out (>1 hour)',
            'message': 'Try with smaller dataset'
        }
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'message': f'Triqler error: {str(e)}'
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VISUALIZATION FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_volcano_plot(data: List[ClassificationResult], expected_changes: Dict) -> go.Figure:
    """Create interactive volcano plot."""
    df = pd.DataFrame([asdict(c) for c in data])
    
    # Color by category
    color_map = {
        'CORRECT': '#2ecc71',           # Green
        'WRONG_MAGNITUDE': '#f39c12',   # Orange
        'WRONG_DIRECTION': '#e74c3c',   # Red
        'FALSE_POSITIVE': '#3498db',    # Blue
        'TRUE_NEGATIVE': '#95a5a6',     # Gray
        'NOT_SIGNIFICANT': '#34495e'    # Dark gray
    }
    
    df['color'] = df['category'].map(color_map)
    
    fig = px.scatter(
        df,
        x='posterior_mean',
        y='diff_exp_prob',
        color='category',
        color_discrete_map=color_map,
        hover_data=['protein_id', 'species', 'tost_p_value'],
        labels={
            'posterior_mean': 'Posterior Mean (log2 FC)',
            'diff_exp_prob': 'Probability of DE',
            'category': 'Classification'
        },
        title='Volcano Plot: Classification by Posterior Statistics'
    )
    
    fig.update_layout(height=600, hovermode='closest')
    return fig


def create_sunburst_chart(data: List[ClassificationResult]) -> go.Figure:
    """Create sunburst chart showing classification breakdown."""
    df = pd.DataFrame([asdict(c) for c in data])
    
    # Summary by species and category
    summary = df.groupby(['species', 'category']).size().reset_index(name='count')
    
    color_map = {
        'CORRECT': '#2ecc71',
        'WRONG_MAGNITUDE': '#f39c12',
        'WRONG_DIRECTION': '#e74c3c',
        'FALSE_POSITIVE': '#3498db',
        'TRUE_NEGATIVE': '#95a5a6',
        'NOT_SIGNIFICANT': '#34495e'
    }
    
    fig = go.Figure(go.Sunburst(
        labels=['All'] + summary['species'].unique().tolist() + summary['category'].unique().tolist(),
        parents=[''] + ['All']*len(summary['species'].unique()) + ['All']*len(summary['category'].unique()),
        values=[len(df)] + summary.groupby('species')['count'].sum().tolist() + summary.groupby('category')['count'].sum().tolist(),
        marker=dict(
            colorscale='RdYlGn',
            cmid=0
        )
    ))
    
    fig.update_layout(
        title='Protein Classification Breakdown',
        height=600,
        font=dict(size=12)
    )
    
    return fig


def create_distribution_plot(data: List[ClassificationResult], species: str) -> go.Figure:
    """Create distribution plot for a species."""
    df = pd.DataFrame([asdict(c) for c in data])
    species_data = df[df['species'] == species]
    
    if len(species_data) == 0:
        return go.Figure().add_annotation(text="No data for this species")
    
    fig = go.Figure()
    
    # Histogram of posterior means
    fig.add_trace(go.Histogram(
        x=species_data['posterior_mean'],
        name='Posterior Mean',
        nbinsx=30,
        opacity=0.7
    ))
    
    # Expected value line
    expected_fc = species_data['expected_log2fc'].iloc[0] if len(species_data) > 0 else 0
    fig.add_vline(
        x=expected_fc,
        line_dash='dash',
        line_color='red',
        annotation_text=f'Expected: {expected_fc:.2f}',
        annotation_position='top right'
    )
    
    fig.update_layout(
        title=f'Fold Change Distribution: {species}',
        xaxis_title='log2 Fold Change',
        yaxis_title='Count',
        height=500,
        hovermode='x unified'
    )
    
    return fig


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STREAMLIT APPLICATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """Main Streamlit application."""
    
    # Page config
    st.set_page_config(
        page_title="Proteomics Benchmark Analyzer",
        page_icon="ðŸ”¬",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Initialize session state
    if 'data' not in st.session_state:
        st.session_state.data = None
    if 'classifications' not in st.session_state:
        st.session_state.classifications = None
    if 'triqler_completed' not in st.session_state:
        st.session_state.triqler_completed = False
    
    # Title
    st.title("ðŸ”¬ Proteomics Benchmark Analyzer with Triqler")
    st.markdown("""
    Multi-species DIA-MS benchmark analysis with Bayesian fold-change posteriors.
    Complete pipeline: Spectronaut â†’ Triqler â†’ Classification â†’ Metrics â†’ Visualization
    """)
    
    # Sidebar configuration
    with st.sidebar:
        st.header("âš™ï¸ Configuration")
        
        # Expected fold changes
        st.subheader("Expected Fold Changes (log2)")
        expected_fc_human = st.slider("Human (background)", -2.0, 2.0, 0.0, 0.1)
        expected_fc_yeast = st.slider("Yeast", -2.0, 2.0, 1.0, 0.1)
        expected_fc_ecoli = st.slider("E. coli", -2.0, 2.0, -1.0, 0.1)
        
        expected_fold_changes = {
            'human': expected_fc_human,
            'yeast': expected_fc_yeast,
            'ecoli': expected_fc_ecoli
        }
        
        # Statistical parameters
        st.subheader("Statistical Parameters")
        tolerance = st.slider("Equivalence Tolerance (Î´)", 0.1, 1.0, 0.3, 0.05)
        alpha = st.slider("Significance Level (Î±)", 0.01, 0.1, 0.05, 0.01)
        
        st.session_state.expected_fold_changes = expected_fold_changes
        st.session_state.tolerance = tolerance
        st.session_state.alpha = alpha
    
    # Main tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ðŸ“¥ Data Preview",
        "âš™ï¸ Processing",
        "ðŸ“Š Classification",
        "ðŸ“ˆ Metrics",
        "ðŸ“‰ Visualizations"
    ])
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 1: DATA PREVIEW
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    with tab1:
        st.header("Data Upload & Preview")
        
        uploaded_file = st.file_uploader(
            "Upload Spectronaut TSV or CSV export",
            type=['tsv', 'csv', 'txt'],
            help="Export from Spectronaut with raw intensities"
        )
        
        if uploaded_file is not None:
            try:
                # Detect delimiter
                sample = uploaded_file.getvalue().decode('utf-8').split('\n')[0]
                delimiter = '\t' if '\t' in sample else ','
                
                # Load data
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, sep=delimiter, low_memory=False)
                
                st.session_state.data = df
                
                st.success(f"âœ… Loaded {len(df)} rows Ã— {len(df.columns)} columns")
                
                # Show statistics
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Total Rows", len(df))
                with col2:
                    st.metric("Total Columns", len(df.columns))
                with col3:
                    st.metric("File Size", f"{uploaded_file.size / 1024:.1f} KB")
                
                # Show preview
                st.subheader("Data Preview")
                st.dataframe(df.head(10), use_container_width=True)
                
                # Check required columns
                required = ['R.FileName', 'R.Condition', 'FG.Charge', 'EG.Cscore',
                           'FG.MS2RawQuantity', 'EG.ModifiedSequence', 'PG.ProteinGroups', 'EG.IsDecoy']
                missing = [col for col in required if col not in df.columns]
                
                if missing:
                    st.warning(f"âš ï¸ Missing columns: {missing}")
                    st.info("Required Spectronaut columns: " + ", ".join(required))
                else:
                    st.info("âœ… All required columns present")
                
                # Show sample values
                with st.expander("Column Information"):
                    st.write(df.dtypes)
                    st.write(df.describe())
                    
            except Exception as e:
                st.error(f"âŒ Error loading file: {str(e)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 2: PROCESSING
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    with tab2:
        st.header("Triqler Processing")
        
        if st.session_state.data is None:
            st.warning("âš ï¸ Please upload data in Tab 1 first")
        else:
            # Convert to Triqler format
            st.subheader("1. Spectronaut â†’ Triqler Conversion")
            
            try:
                triqler_df = convert_to_triqler_format(st.session_state.data)
                st.success(f"âœ… Converted {len(triqler_df)} rows to Triqler format")
                
                st.write("**Triqler Input Format:**")
                st.dataframe(triqler_df.head(10), use_container_width=True)
                
                st.session_state.triqler_df = triqler_df
                
                # Species distribution
                col1, col2 = st.columns(2)
                with col1:
                    species_counts = st.session_state.data['PG.Organisms'].apply(
                        lambda x: infer_species(x, '')
                    ).value_counts()
                    st.write("Species Distribution:")
                    st.bar_chart(species_counts)
                
                with col2:
                    condition_counts = st.session_state.data['R.Condition'].value_counts()
                    st.write("Condition Distribution:")
                    st.bar_chart(condition_counts)
                    
            except Exception as e:
                st.error(f"âŒ Conversion error: {str(e)}")
            
            # Run Triqler
            st.subheader("2. Run Triqler Analysis")
            
            if st.button("â–¶ï¸ Run Triqler", key="run_triqler", use_container_width=True):
                with st.spinner("Running Triqler (this may take 2-10 minutes)..."):
                    try:
                        # Create temp directory
                        with tempfile.TemporaryDirectory() as tmpdir:
                            # Write Triqler input
                            triqler_input_file = os.path.join(tmpdir, 'triqler_input.tsv')
                            st.session_state.triqler_df.to_csv(
                                triqler_input_file, sep='\t', index=False
                            )
                            
                            # Run Triqler
                            result = run_triqler(triqler_input_file, tmpdir)
                            
                            if result['success']:
                                st.success(f"âœ… {result['message']}")
                                
                                # Extract posteriors
                                posteriors = extract_triqler_posteriors(
                                    result['protein_posteriors'],
                                    result['fold_change_posteriors']
                                )
                                
                                st.session_state.posteriors = posteriors
                                st.session_state.triqler_completed = True
                                
                                st.info(f"Extracted posteriors for {len(posteriors)} proteins")
                                
                            else:
                                st.error(f"âŒ {result.get('message', result.get('error', 'Unknown error'))}")
                                
                                # Show troubleshooting
                                with st.expander("ðŸ”§ Troubleshooting"):
                                    st.write("""
                                    Common issues:
                                    1. Triqler not installed: `pip install triqler`
                                    2. Missing input columns: Check Spectronaut export
                                    3. No decoys: Some workflows require decoy proteins
                                    4. Too many decoys: Filter before upload
                                    """)
                                    
                    except Exception as e:
                        st.error(f"âŒ Error: {str(e)}")
                        st.error(traceback.format_exc())
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 3: CLASSIFICATION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    with tab3:
        st.header("Protein Classification")
        
        if not st.session_state.triqler_completed:
            st.warning("âš ï¸ Please run Triqler in Tab 2 first")
        else:
            st.subheader("Classification Summary")
            
            try:
                # Prepare data for classification
                data_with_posteriors = []
                
                for protein_id, posterior in st.session_state.posteriors.items():
                    # Get species from original data
                    protein_rows = st.session_state.data[
                        st.session_state.data['PG.ProteinGroups'].astype(str) == protein_id
                    ]
                    
                    if len(protein_rows) == 0:
                        continue
                    
                    species = infer_species(
                        protein_rows.iloc[0]['PG.Organisms'],
                        protein_id
                    )
                    
                    # Calculate observed log2 FC
                    obs_log2fc = np.log2(protein_rows['FG.MS2RawQuantity'].mean() + 1)
                    
                    data_with_posteriors.append({
                        'protein_id': protein_id,
                        'species': species,
                        'observed_log2fc': obs_log2fc,
                        'posterior_mean': posterior['mean'],
                        'posterior_std': posterior['std'],
                        'posterior_ci_lower': posterior['ci_lower'],
                        'posterior_ci_upper': posterior['ci_upper'],
                        'diff_exp_prob': 0.5 + np.abs(posterior['mean']) / (np.abs(posterior['mean']) + posterior['std']) * 0.5,
                        'pep': 0.01
                    })
                
                df_classify = pd.DataFrame(data_with_posteriors)
                
                # Classify proteins
                classifications = classify_proteins(
                    df_classify,
                    st.session_state.expected_fold_changes,
                    st.session_state.tolerance,
                    st.session_state.alpha
                )
                
                st.session_state.classifications = classifications
                
                # Summary metrics
                col1, col2, col3, col4, col5, col6 = st.columns(6)
                
                category_counts = {}
                for c in classifications:
                    category_counts[c.category] = category_counts.get(c.category, 0) + 1
                
                with col1:
                    st.metric("CORRECT", category_counts.get('CORRECT', 0))
                with col2:
                    st.metric("WRONG_MAG", category_counts.get('WRONG_MAGNITUDE', 0))
                with col3:
                    st.metric("WRONG_DIR", category_counts.get('WRONG_DIRECTION', 0))
                with col4:
                    st.metric("FALSE_POS", category_counts.get('FALSE_POSITIVE', 0))
                with col5:
                    st.metric("TRUE_NEG", category_counts.get('TRUE_NEGATIVE', 0))
                with col6:
                    st.metric("NOT_SIG", category_counts.get('NOT_SIGNIFICANT', 0))
                
                # Detailed results
                st.subheader("Detailed Results")
                
                results_df = pd.DataFrame([asdict(c) for c in classifications])
                st.dataframe(
                    results_df[['protein_id', 'species', 'posterior_mean', 'posterior_std',
                               'diff_exp_prob', 'category', 'tost_p_value']],
                    use_container_width=True
                )
                
            except Exception as e:
                st.error(f"âŒ Classification error: {str(e)}")
                st.error(traceback.format_exc())
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 4: METRICS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    with tab4:
        st.header("Benchmark Metrics")
        
        if st.session_state.classifications is None:
            st.warning("âš ï¸ Please classify proteins in Tab 3 first")
        else:
            try:
                classifications = st.session_state.classifications
                
                # Overall metrics
                st.subheader("Overall Performance")
                
                defdr = calculate_defdr(classifications)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric(
                        "deFDR (Directional Error Rate)",
                        f"{defdr:.2%}",
                        delta="Lower is better",
                        delta_color="inverse"
                    )
                    st.write("Fraction of significant proteins with wrong category")
                
                with col2:
                    correct_count = sum(1 for c in classifications if c.category == 'CORRECT')
                    total_count = len(classifications)
                    accuracy = correct_count / total_count if total_count > 0 else 0
                    st.metric(
                        "Accuracy (CORRECT)",
                        f"{accuracy:.2%}",
                        delta="Higher is better"
                    )
                
                # Species-specific metrics
                st.subheader("Species-Specific Metrics")
                
                species_list = list(set(c.species for c in classifications))
                
                for species in species_list:
                    species_classifications = [c for c in classifications if c.species == species]
                    
                    if len(species_classifications) == 0:
                        continue
                    
                    with st.expander(f"ðŸ“Š {species.upper()} ({len(species_classifications)} proteins)"):
                        col1, col2, col3, col4 = st.columns(4)
                        
                        # Asymmetry factor
                        log2fcs = np.array([c.posterior_mean for c in species_classifications])
                        asym = calculate_asymmetry_factor(log2fcs)
                        
                        with col1:
                            st.metric(
                                "Asymmetry",
                                f"{asym:.2f}",
                                help="1.0 = symmetric, <0.5 = very skewed"
                            )
                        
                        # Cpk
                        expected_fc = st.session_state.expected_fold_changes.get(species, 0.0)
                        cpk = calculate_cpk(log2fcs, expected_fc, st.session_state.tolerance)
                        
                        with col2:
                            st.metric(
                                "Cpk (Capability)",
                                f"{cpk:.2f}",
                                help=">1.33 = capable, >1.67 = excellent"
                            )
                        
                        # RMSE
                        rmse = calculate_rmse(log2fcs, expected_fc)
                        
                        with col3:
                            st.metric(
                                "RMSE",
                                f"{rmse:.3f}",
                                help="<0.3 = excellent accuracy"
                            )
                        
                        # Correct percentage
                        correct = sum(1 for c in species_classifications if c.category == 'CORRECT')
                        correct_pct = correct / len(species_classifications) * 100
                        
                        with col4:
                            st.metric(
                                "Correct %",
                                f"{correct_pct:.1f}%",
                                help="Percentage correctly classified"
                            )
                        
                        # Distribution plot
                        st.write("**Distribution:**")
                        dist_fig = create_distribution_plot(species_classifications, species)
                        st.plotly_chart(dist_fig, use_container_width=True)
                        
            except Exception as e:
                st.error(f"âŒ Metrics error: {str(e)}")
                st.error(traceback.format_exc())
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 5: VISUALIZATIONS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    with tab5:
        st.header("Interactive Visualizations")
        
        if st.session_state.classifications is None:
            st.warning("âš ï¸ Please classify proteins in Tab 3 first")
        else:
            try:
                classifications = st.session_state.classifications
                
                # Volcano plot
                st.subheader("Volcano Plot")
                volcano_fig = create_volcano_plot(classifications, st.session_state.expected_fold_changes)
                st.plotly_chart(volcano_fig, use_container_width=True)
                
                # Sunburst chart
                st.subheader("Classification Breakdown")
                sunburst_fig = create_sunburst_chart(classifications)
                st.plotly_chart(sunburst_fig, use_container_width=True)
                
                # Category distribution
                st.subheader("Category Distribution")
                category_df = pd.DataFrame([
                    {'Category': c.category, 'Count': 1}
                    for c in classifications
                ])
                category_summary = category_df.groupby('Category').size()
                st.bar_chart(category_summary)
                
            except Exception as e:
                st.error(f"âŒ Visualization error: {str(e)}")
                st.error(traceback.format_exc())
    
    # Footer
    st.markdown("---")
    st.markdown("""
    **Proteomics Benchmark Analyzer v1.0.0** â€¢ Built with Triqler
    
    Citation: The, M. & KÃ¤ll, L. (2019) Integrated identification and quantification error probabilities.
    Molecular & Cellular Proteomics, 18(3), 561-570.
    """)


if __name__ == '__main__':
    main()
